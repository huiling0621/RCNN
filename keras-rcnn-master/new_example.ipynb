{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对图像进行压缩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image  #Python的图像处理库\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'image'\n",
    "for i in os.listdir(DIR):\n",
    "        path = os.path.join(DIR,i) #找到图片路径\n",
    "       # img_resize(path,\"im\",224,224)  #根据路径打开图片\n",
    "        img = Image.open(path)        \n",
    "        new_image = img.resize((224,224),Image.BILINEAR)\n",
    "        new_image=new_image.convert('RGB')\n",
    "        new_image.save(os.path.join('im',os.path.basename(path)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用labelme对压缩后的图形进行贴标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "import codecs\n",
    "import hashlib\n",
    "import json\n",
    "import os.path\n",
    "import shutil\n",
    "import uuid\n",
    "import skimage.draw\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "analysis_root_dir = \"C:/Users/zhuhuiling/Desktop/scratch1\"\n",
    "path = Path(analysis_root_dir)\n",
    "all_json_file = list(path.glob('**/*.json'))\n",
    "parse_result = []\n",
    "for json_file in all_json_file:\n",
    "    # 获取所在目录的名称\n",
    "    service_name = json_file.parent.stem\n",
    "    with json_file.open() as f:\n",
    "        json_result = json.load(f)\n",
    "    parse_result.append(json_result) \n",
    "\n",
    "\n",
    "r,c=(224,224)\n",
    "groups = (\"training1\", \"test1\")\n",
    "for group in groups:\n",
    "    dictionaries = [] \n",
    "    for i in parse_result[0:20]: \n",
    "        pathname = \"im/\"+ i[\"imagePath\"]\n",
    "        if os.path.exists(path):\n",
    "            dictionary = {\n",
    "                        \"image\": {\n",
    "                        \"pathname\": pathname,\n",
    "                        \"shape\": {\n",
    "                                \"r\": r,\n",
    "                                \"c\": c,\n",
    "                                \"channels\": 3\n",
    "                            }\n",
    "                        },\n",
    "                        \"objects\": []\n",
    "                    }\n",
    "            for j in i[\"shapes\"]:\n",
    "                category = j['label']\n",
    "                (bounding_box_r, bounding_box_c)=j['points']\n",
    "                maximum_r=max(bounding_box_r)  \n",
    "                minimum_r= min(bounding_box_r)\n",
    "                minimum_c = min(bounding_box_c)\n",
    "                maximum_c= max(bounding_box_c)\n",
    "                object_dictionary = {\n",
    "                        \"bounding_box\": {\n",
    "                             \"minimum\": {\n",
    "                                 \"r\": minimum_r - 1,\n",
    "                                 \"c\": minimum_c - 1\n",
    "                         },\n",
    "                         \"maximum\": {\n",
    "                                \"r\": maximum_r - 1,\n",
    "                                \"c\": maximum_c - 1\n",
    "                            }\n",
    "                       },\n",
    "                        \"category\": category\n",
    "                    }\n",
    "                dictionary[\"objects\"].append(object_dictionary)\n",
    "            dictionaries.append(dictionary)\n",
    "            filename = \"{}.json\".format(group)\n",
    "            with open(filename, \"w\") as stream:\n",
    "                json.dump(dictionaries, stream)#dumps是将dict转化成str格式，loads是将str转化成dict格式。\n",
    "\n",
    "\n",
    "#得到training1.json和test.json        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将json文档转换成标准格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os.path\n",
    "import shutil\n",
    "import uuid\n",
    "import skimage.draw\n",
    "import skimage.io\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5sum(pathname, blocksize=65536):\n",
    "    checksum = hashlib.md5()##md5对象，md5不能反解，但是加密是固定的，就是关系是一一对应，所以有缺陷，可以被对撞出来,其作用就是加密\n",
    "\n",
    "    with open(pathname, \"rb\") as stream:\n",
    "        for block in iter(lambda: stream.read(blocksize), b\"\"):\n",
    "            checksum.update(block)\n",
    "\n",
    "    return checksum.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "analysis_root_dir = \"C:/Users/zhuhuiling/Desktop/scratch1\"#存放所有.json文档的地方\n",
    "path = Path(analysis_root_dir)\n",
    "all_json_file = list(path.glob('**/*.json'))\n",
    "parse_result = []\n",
    "for json_file in all_json_file:\n",
    "    # 获取所在目录的名称\n",
    "    service_name = json_file.parent.stem\n",
    "    with json_file.open() as f:\n",
    "        json_result = json.load(f)\n",
    "    parse_result.append(json_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,c = (224,224)\n",
    "groups = (\"training1\", \"test1\")\n",
    "for group in groups:\n",
    "    dictionaries = [] \n",
    "    for i in parse_result[:256]: \n",
    "        pathname = \"im/\"+ i[\"imagePath\"]\n",
    "        if os.path.exists(path):\n",
    "            dictionary = {\n",
    "                        \"image\": {\n",
    "                        \"pathname\": pathname,\n",
    "                        \"shape\": {\n",
    "                                \"r\": r,\n",
    "                                \"c\": c,\n",
    "                                \"channels\": 3\n",
    "                            }\n",
    "                        },\n",
    "                        \"objects\": []\n",
    "                    }\n",
    "            for j in i[\"shapes\"]:\n",
    "                category = j['label']\n",
    "                (bounding_box_r, bounding_box_c)=j['points']\n",
    "                minimum_r, maximum_r = bounding_box_r\n",
    "                minimum_c, maximum_c = bounding_box_c\n",
    "                object_dictionary = {\n",
    "                        \"bounding_box\": {\n",
    "                             \"minimum\": {\n",
    "                                 \"r\": minimum_r - 1,\n",
    "                                 \"c\": minimum_c - 1\n",
    "                         },\n",
    "                         \"maximum\": {\n",
    "                                \"r\": maximum_r - 1,\n",
    "                                \"c\": maximum_c - 1\n",
    "                            }\n",
    "                       },\n",
    "                        \"category\": category\n",
    "                    }\n",
    "                dictionary[\"objects\"].append(object_dictionary)\n",
    "            dictionaries.append(dictionary)\n",
    "            filename = \"{}.json\".format(group)\n",
    "            with open(filename, \"w\") as stream:\n",
    "                json.dump(dictionaries, stream)#dumps是将dict转化成str格式，loads是将str转化成dict格式。\n",
    "\n",
    "\n",
    "        \n",
    " #上述代码的作用是将所有数据分为测试集和训练集       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将测试集和训练集的.json的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 38s 4s/step - loss: 13.1808 - val_loss: 11.5711\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 37s 4s/step - loss: 11.6839 - val_loss: 47.8803\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 41s 4s/step - loss: 37.8700 - val_loss: 10.5162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x236201f0dd8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "A simple example for ploting two figures of a exponential\n",
    "function in order to test the autonomy of the gallery\n",
    "stacking multiple images.\n",
    "\"\"\"\n",
    "\n",
    "import keras\n",
    "import keras_rcnn\n",
    "import keras_rcnn.datasets.shape \n",
    "import keras_rcnn.preprocessing\n",
    "import keras_rcnn.models\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import jsonschema\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    resource_path = \"/\".join([\"data1\", \"schema.json\"])\n",
    "\n",
    "    with open(pkg_resources.resource_filename(\"keras_rcnn\", resource_path)) as stream:\n",
    "        schema = json.load(stream)\n",
    "\n",
    "    resource_path = \"/\".join([\"data1\", \"shape\", \"training1.json\"])\n",
    "\n",
    "    with open(pkg_resources.resource_filename(\"keras_rcnn\", resource_path)) as stream:\n",
    "        training_dictionary = json.load(stream)\n",
    "\n",
    "    jsonschema.validate(training_dictionary, schema)\n",
    "\n",
    "    for dictionary in training_dictionary:\n",
    "        resource_path = \"/\".join([\"data1\", \"shape\", dictionary[\"image\"][\"pathname\"]])\n",
    "        pathname = pkg_resources.resource_filename(\"keras_rcnn\", resource_path)\n",
    "        dictionary[\"image\"][\"pathname\"] = pathname\n",
    "\n",
    "    resource_path = \"/\".join([\"data1\", \"shape\", \"test1.json\"])\n",
    "\n",
    "    with open(pkg_resources.resource_filename(\"keras_rcnn\", resource_path)) as stream:\n",
    "        test_dictionary = json.load(stream)\n",
    "\n",
    "    jsonschema.validate(test_dictionary, schema)\n",
    "\n",
    "    for dictionary in test_dictionary:\n",
    "        resource_path = \"/\".join([\"data1\", \"shape\", dictionary[\"image\"][\"pathname\"]])\n",
    "        pathname = pkg_resources.resource_filename(\"keras_rcnn\", resource_path)\n",
    "        dictionary[\"image\"][\"pathname\"] = pathname\n",
    "\n",
    "    return training_dictionary, test_dictionary\n",
    "\n",
    "\n",
    "training_dictionary, test_dictionary = load_data()\n",
    "training_dictionary\n",
    "\n",
    "#开始训练模型\n",
    "categories = {\"scratch\":1}\n",
    "\n",
    "generator = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
    "\n",
    "generator = generator.flow_from_dictionary(\n",
    "        dictionary=training_dictionary,\n",
    "        categories=categories,\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "validation_data = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
    "validation_data = validation_data.flow_from_dictionary(\n",
    "        dictionary=test_dictionary,\n",
    "        categories=categories,\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "validation_data\n",
    "keras.backend.set_learning_phase(1)\n",
    "model = keras_rcnn.models.RCNN(\n",
    "        categories = {\"scratch\":1},\n",
    "        dense_units=512,\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(optimizer)\n",
    "\n",
    "model.fit_generator(\n",
    "        epochs=3,\n",
    "        generator=generator,\n",
    "        validation_data=validation_data\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bounding boxes\n",
    "==============\n",
    "\n",
    "A simple example for ploting two figures of a exponential\n",
    "function in order to test the autonomy of the gallery\n",
    "stacking multiple images.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy\n",
    "import keras_rcnn.datasets.shape\n",
    "import keras_rcnn.preprocessing\n",
    "import keras_rcnn.utils\n",
    "\n",
    "\n",
    "def main():\n",
    "    training_dictionary, test_dictionary \n",
    "\n",
    "    categories = {\"scratch\":1}\n",
    "\n",
    "    generator = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
    "\n",
    "    generator = generator.flow_from_dictionary(\n",
    "        dictionary=training_dictionary,\n",
    "        categories=categories,\n",
    "        target_size=(224, 224),\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    target, _ = generator.next()\n",
    "\n",
    "    target_bounding_boxes, target_categories, target_images, target_masks, _ = target\n",
    "\n",
    "    target_bounding_boxes = numpy.squeeze(target_bounding_boxes)\n",
    "\n",
    "    target_images = numpy.squeeze(target_images)\n",
    "\n",
    "    target_categories = numpy.argmax(target_categories, -1)\n",
    "\n",
    "    target_categories = numpy.squeeze(target_categories)\n",
    "\n",
    "    keras_rcnn.utils.show_bounding_boxes(target_images, target_bounding_boxes, target_categories)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7c310566a83d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-afa0c852f885>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mtarget_categories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_categories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mkeras_rcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_bounding_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_bounding_boxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_categories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\keras-rcnn-master\\keras_rcnn\\utils\\_visualization.py\u001b[0m in \u001b[0;36mshow_bounding_boxes\u001b[1;34m(image, bounding_boxes, categories)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mbounding_boxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
