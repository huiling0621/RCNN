{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os.path\n",
    "import shutil\n",
    "import uuid\n",
    "\n",
    "import skimage.draw\n",
    "import skimage.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5sum(pathname, blocksize=65536):\n",
    "    checksum = hashlib.md5()##md5对象，md5不能反解，但是加密是固定的，就是关系是一一对应，所以有缺陷，可以被对撞出来,其作用就是加密\n",
    "\n",
    "    with open(pathname, \"rb\") as stream:\n",
    "        for block in iter(lambda: stream.read(blocksize), b\"\"):\n",
    "            checksum.update(block)\n",
    "\n",
    "    return checksum.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "import codecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scratch'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "analysis_root_dir = \"C:/Users/zhuhuiling/Desktop/scratch1\"\n",
    "path = Path(analysis_root_dir)\n",
    "all_json_file = list(path.glob('**/*.json'))\n",
    "parse_result = []\n",
    "for json_file in all_json_file:\n",
    "    # 获取所在目录的名称\n",
    "    service_name = json_file.parent.stem\n",
    "    with json_file.open() as f:\n",
    "        json_result = json.load(f)\n",
    "    parse_result.append(json_result) \n",
    "\n",
    "a=parse_result[1]['shapes'][0]['label']\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = (\"training1\", \"test1\")\n",
    "for group in groups:\n",
    "    dictionaries = [] \n",
    "    for i in parse_result[:256]: \n",
    "        pathname = \"im/\"+ i[\"imagePath\"]\n",
    "        if os.path.exists(path):\n",
    "            dictionary = {\n",
    "                        \"image\": {\n",
    "                        \"pathname\": pathname,\n",
    "                        \"shape\": {\n",
    "                                \"r\": r,\n",
    "                                \"c\": c,\n",
    "                                \"channels\": 3\n",
    "                            }\n",
    "                        },\n",
    "                        \"objects\": []\n",
    "                    }\n",
    "            for j in i[\"shapes\"]:\n",
    "                category = j['label']\n",
    "                (bounding_box_r, bounding_box_c)=j['points']\n",
    "                minimum_r, maximum_r = bounding_box_r\n",
    "                minimum_c, maximum_c = bounding_box_c\n",
    "                object_dictionary = {\n",
    "                        \"bounding_box\": {\n",
    "                             \"minimum\": {\n",
    "                                 \"r\": minimum_r - 1,\n",
    "                                 \"c\": minimum_c - 1\n",
    "                         },\n",
    "                         \"maximum\": {\n",
    "                                \"r\": maximum_r - 1,\n",
    "                                \"c\": maximum_c - 1\n",
    "                            }\n",
    "                       },\n",
    "                        \"category\": category\n",
    "                    }\n",
    "                dictionary[\"objects\"].append(object_dictionary)\n",
    "            dictionaries.append(dictionary)\n",
    "            filename = \"{}.json\".format(group)\n",
    "            with open(filename, \"w\") as stream:\n",
    "                json.dump(dictionaries, stream)#dumps是将dict转化成str格式，loads是将str转化成dict格式。\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-31e18bbdf741>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m                         \u001b[1;34m\"objects\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     }\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mcategory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shapes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mbounding_box_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounding_box_c\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shapes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'points'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#需要修改\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mminimum_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaximum_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbounding_box_r\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "groups = (\"training1\", \"test1\")\n",
    "for group in groups:\n",
    "    dictionaries = [] \n",
    "    for i in parse_result[:256]: \n",
    "        pathname = \"im/\"+ i[\"imagePath\"]\n",
    "        if os.path.exists(path):\n",
    "            dictionary = {\n",
    "                        \"image\": {\n",
    "                        \"pathname\": pathname,\n",
    "                        \"shape\": {\n",
    "                                \"r\": r,\n",
    "                                \"c\": c,\n",
    "                                \"channels\": 3\n",
    "                            }\n",
    "                        },\n",
    "                        \"objects\": []\n",
    "                    }\n",
    "        category = i['shapes'][0]['label']\n",
    "        (bounding_box_r, bounding_box_c) =  i['shapes'][0]['points']#需要修改\n",
    "        minimum_r, maximum_r = bounding_box_r\n",
    "        minimum_c, maximum_c = bounding_box_c\n",
    "        object_dictionary = {\n",
    "                        \"bounding_box\": {\n",
    "                             \"minimum\": {\n",
    "                                 \"r\": minimum_r - 1,\n",
    "                                 \"c\": minimum_c - 1\n",
    "                         },\n",
    "                         \"maximum\": {\n",
    "                                \"r\": maximum_r - 1,\n",
    "                                \"c\": maximum_c - 1\n",
    "                         }\n",
    "                   },\n",
    "                        \"category\": category\n",
    "                }\n",
    "        dictionary[\"objects\"].append(object_dictionary)\n",
    "        dictionaries.append(dictionary)\n",
    "        filename = \"{}.json\".format(group)\n",
    "        with open(filename, \"w\") as stream:\n",
    "            json.dump(dictionaries, stream)#dumps是将dict转化成str格式，loads是将str转化成dict格式。\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A simple example for ploting two figures of a exponential\n",
    "function in order to test the autonomy of the gallery\n",
    "stacking multiple images.\n",
    "\"\"\"\n",
    "\n",
    "import keras\n",
    "import keras_rcnn\n",
    "import keras_rcnn.datasets.shape \n",
    "import keras_rcnn.preprocessing\n",
    "import keras_rcnn.models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import jsonschema\n",
    "\n",
    "import pkg_resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
