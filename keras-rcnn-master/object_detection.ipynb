{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A simple example for ploting two figures of a exponential\n",
    "function in order to test the autonomy of the gallery\n",
    "stacking multiple images.\n",
    "\"\"\"\n",
    "\n",
    "import keras\n",
    "import keras_rcnn\n",
    "import keras_rcnn.datasets.shape \n",
    "import keras_rcnn.preprocessing\n",
    "import keras_rcnn.models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    training_dictionary, test_dictionary = keras_rcnn.datasets.shape.load_data()\n",
    "\n",
    "    categories = {\"circle\": 1, \"rectangle\": 2, \"triangle\": 3}\n",
    "\n",
    "    generator = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
    "\n",
    "    generator = generator.flow_from_dictionary(\n",
    "        dictionary=training_dictionary,\n",
    "        categories=categories,\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "\n",
    "    validation_data = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
    "\n",
    "    validation_data = validation_data.flow_from_dictionary(\n",
    "        dictionary=test_dictionary,\n",
    "        categories=categories,\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "\n",
    "    keras.backend.set_learning_phase(1)\n",
    "\n",
    "    model = keras_rcnn.models.RCNN(\n",
    "        categories=[\"circle\", \"rectangle\", \"triangle\"],\n",
    "        dense_units=512,\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(optimizer)\n",
    "\n",
    "    model.fit_generator(\n",
    "        epochs=3,\n",
    "        generator=generator,\n",
    "        validation_data=validation_data\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "D:\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 1012s 4s/step - loss: 4.1892 - val_loss: 2.1667\n",
      "Epoch 2/3\n",
      "256/256 [==============================] - 1007s 4s/step - loss: 2.1594 - val_loss: 2.0445\n",
      "Epoch 3/3\n",
      "256/256 [==============================] - 966s 4s/step - loss: 2.0947 - val_loss: 2.1190\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
