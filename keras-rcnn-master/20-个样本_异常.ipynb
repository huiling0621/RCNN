{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "import codecs\n",
    "import hashlib\n",
    "import json\n",
    "import os.path\n",
    "import shutil\n",
    "import uuid\n",
    "import skimage.draw\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "analysis_root_dir = \"C:/Users/zhuhuiling/Desktop/scratch1\"\n",
    "path = Path(analysis_root_dir)\n",
    "all_json_file = list(path.glob('**/*.json'))\n",
    "parse_result = []\n",
    "for json_file in all_json_file:\n",
    "    # 获取所在目录的名称\n",
    "    service_name = json_file.parent.stem\n",
    "    with json_file.open() as f:\n",
    "        json_result = json.load(f)\n",
    "    parse_result.append(json_result) \n",
    "\n",
    "\n",
    "r,c=(224,224)\n",
    "groups = (\"training4\", \"test4\")\n",
    "for group in groups:\n",
    "    dictionaries = [] \n",
    "    for i in parse_result[51:122]: \n",
    "        pathname = \"im/\"+ i[\"imagePath\"]\n",
    "        if os.path.exists(path):\n",
    "            dictionary = {\n",
    "                        \"image\": {\n",
    "                        \"pathname\": pathname,\n",
    "                        \"shape\": {\n",
    "                                \"r\": r,\n",
    "                                \"c\": c,\n",
    "                                \"channels\": 3\n",
    "                            }\n",
    "                        },\n",
    "                        \"objects\": []\n",
    "                    }\n",
    "            for j in i[\"shapes\"]:\n",
    "                category = j['label']\n",
    "                (bounding_box_r, bounding_box_c)=j['points']\n",
    "                maximum_r=max(bounding_box_r)  \n",
    "                minimum_r= min(bounding_box_r)\n",
    "                minimum_c = min(bounding_box_c)\n",
    "                maximum_c= max(bounding_box_c)\n",
    "                object_dictionary = {\n",
    "                        \"bounding_box\": {\n",
    "                             \"minimum\": {\n",
    "                                 \"r\": minimum_r - 1,\n",
    "                                 \"c\": minimum_c - 1\n",
    "                         },\n",
    "                         \"maximum\": {\n",
    "                                \"r\": maximum_r - 1,\n",
    "                                \"c\": maximum_c - 1\n",
    "                            }\n",
    "                       },\n",
    "                        \"category\": category\n",
    "                    }\n",
    "                dictionary[\"objects\"].append(object_dictionary)\n",
    "            dictionaries.append(dictionary)\n",
    "            filename = \"{}.json\".format(group)\n",
    "            with open(filename, \"w\") as stream:\n",
    "                json.dump(dictionaries, stream)#dumps是将dict转化成str格式，loads是将str转化成dict格式。\n",
    "\n",
    "\n",
    "#得到training1.json和test.json     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A simple example for ploting two figures of a exponential\n",
    "function in order to test the autonomy of the gallery\n",
    "stacking multiple images.\n",
    "\"\"\"\n",
    "\n",
    "import keras\n",
    "import keras_rcnn\n",
    "import keras_rcnn.datasets.shape \n",
    "import keras_rcnn.preprocessing\n",
    "import keras_rcnn.models\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import jsonschema\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    resource_path = \"/\".join([\"data1\", \"schema.json\"])\n",
    "\n",
    "    with open(pkg_resources.resource_filename(\"keras_rcnn\", resource_path)) as stream:\n",
    "        schema = json.load(stream)\n",
    "\n",
    "    resource_path = \"/\".join([\"data1\", \"shape\", \"training4.json\"])\n",
    "\n",
    "    with open(pkg_resources.resource_filename(\"keras_rcnn\", resource_path)) as stream:\n",
    "        training_dictionary = json.load(stream)\n",
    "\n",
    "    jsonschema.validate(training_dictionary, schema)\n",
    "\n",
    "    for dictionary in training_dictionary:\n",
    "        resource_path = \"/\".join([\"data1\", \"shape\", dictionary[\"image\"][\"pathname\"]])\n",
    "        pathname = pkg_resources.resource_filename(\"keras_rcnn\", resource_path)\n",
    "        dictionary[\"image\"][\"pathname\"] = pathname\n",
    "\n",
    "    resource_path = \"/\".join([\"data1\", \"shape\", \"test4.json\"])\n",
    "\n",
    "    with open(pkg_resources.resource_filename(\"keras_rcnn\", resource_path)) as stream:\n",
    "        test_dictionary = json.load(stream)\n",
    "\n",
    "    jsonschema.validate(test_dictionary, schema)\n",
    "\n",
    "    for dictionary in test_dictionary:\n",
    "        resource_path = \"/\".join([\"data1\", \"shape\", dictionary[\"image\"][\"pathname\"]])\n",
    "        pathname = pkg_resources.resource_filename(\"keras_rcnn\", resource_path)\n",
    "        dictionary[\"image\"][\"pathname\"] = pathname\n",
    "\n",
    "    return training_dictionary, test_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "D:\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/20 [===========================>..] - ETA: 3s - loss: 96.7175 "
     ]
    }
   ],
   "source": [
    "\n",
    "training_dictionary, test_dictionary = load_data()\n",
    "training_dictionary\n",
    "\n",
    "#开始训练模型\n",
    "categories = {\"scratch\":1}\n",
    "\n",
    "generator = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
    "\n",
    "generator = generator.flow_from_dictionary(\n",
    "        dictionary=training_dictionary,\n",
    "        categories=categories,\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "validation_data = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
    "validation_data = validation_data.flow_from_dictionary(\n",
    "        dictionary=test_dictionary,\n",
    "        categories=categories,\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "validation_data\n",
    "keras.backend.set_learning_phase(1)\n",
    "model = keras_rcnn.models.RCNN(\n",
    "        categories = {\"scratch\":1},\n",
    "        dense_units=512,\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(optimizer)\n",
    "\n",
    "model.fit_generator(\n",
    "        epochs=3,\n",
    "        generator=generator,\n",
    "        validation_data=validation_data\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
