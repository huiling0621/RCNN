{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "import codecs\n",
    "import hashlib\n",
    "import json\n",
    "import os.path\n",
    "import shutil\n",
    "import uuid\n",
    "import skimage.draw\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "analysis_root_dir = \"C:/Users/zhuhuiling/Desktop/scratch1\"\n",
    "path = Path(analysis_root_dir)\n",
    "all_json_file = list(path.glob('**/*.json'))\n",
    "parse_result = []\n",
    "for json_file in all_json_file:\n",
    "    # 获取所在目录的名称\n",
    "    service_name = json_file.parent.stem\n",
    "    with json_file.open() as f:\n",
    "        json_result = json.load(f)\n",
    "    parse_result.append(json_result) \n",
    "\n",
    "\n",
    "r,c=(224,224)\n",
    "groups = (\"training3\", \"test3\")\n",
    "k=1\n",
    "\n",
    "\n",
    "if k == 1:\n",
    "    dictionaries = [] \n",
    "    for i in parse_result[:30]: \n",
    "        pathname = \"im/\"+ i[\"imagePath\"]\n",
    "        if os.path.exists(path):\n",
    "            dictionary = {\n",
    "                        \"image\": {\n",
    "                        \"pathname\": pathname,\n",
    "                        \"shape\": {\n",
    "                                \"r\": r,\n",
    "                                \"c\": c,\n",
    "                                \"channels\": 3\n",
    "                            }\n",
    "                        },\n",
    "                        \"objects\": []\n",
    "                    }\n",
    "            for j in i[\"shapes\"]:\n",
    "                category = j['label']\n",
    "                (bounding_box_r, bounding_box_c)=j['points']\n",
    "                maximum_r=max(bounding_box_r)  \n",
    "                minimum_r= min(bounding_box_r)\n",
    "                minimum_c = min(bounding_box_c)\n",
    "                maximum_c= max(bounding_box_c)\n",
    "                object_dictionary = {\n",
    "                        \"bounding_box\": {\n",
    "                             \"minimum\": {\n",
    "                                 \"r\": minimum_r - 1,\n",
    "                                 \"c\": minimum_c - 1\n",
    "                         },\n",
    "                         \"maximum\": {\n",
    "                                \"r\": maximum_r - 1,\n",
    "                                \"c\": maximum_c - 1\n",
    "                            }\n",
    "                       },\n",
    "                        \"category\": category\n",
    "                    }\n",
    "                dictionary[\"objects\"].append(object_dictionary)\n",
    "            dictionaries.append(dictionary)\n",
    "            filename = \"{}.json\".format(groups[0])\n",
    "            with open(filename, \"w\") as stream:\n",
    "                json.dump(dictionaries, stream)#dumps是将dict转化成str格式，loads是将str转化成dict格式。\n",
    "\n",
    "\n",
    "#得到training1.json和test.json     \n",
    "\n",
    "if k == 1:\n",
    "    dictionaries = [] \n",
    "    for i in parse_result[30:60]: \n",
    "        pathname = \"im/\"+ i[\"imagePath\"]\n",
    "        if os.path.exists(path):\n",
    "            dictionary = {\n",
    "                        \"image\": {\n",
    "                        \"pathname\": pathname,\n",
    "                        \"shape\": {\n",
    "                                \"r\": r,\n",
    "                                \"c\": c,\n",
    "                                \"channels\": 3\n",
    "                            }\n",
    "                        },\n",
    "                        \"objects\": []\n",
    "                    }\n",
    "            for j in i[\"shapes\"]:\n",
    "                category = j['label']\n",
    "                (bounding_box_r, bounding_box_c)=j['points']\n",
    "                maximum_r=max(bounding_box_r)  \n",
    "                minimum_r= min(bounding_box_r)\n",
    "                minimum_c = min(bounding_box_c)\n",
    "                maximum_c= max(bounding_box_c)\n",
    "                object_dictionary = {\n",
    "                        \"bounding_box\": {\n",
    "                             \"minimum\": {\n",
    "                                 \"r\": minimum_r - 1,\n",
    "                                 \"c\": minimum_c - 1\n",
    "                         },\n",
    "                         \"maximum\": {\n",
    "                                \"r\": maximum_r - 1,\n",
    "                                \"c\": maximum_c - 1\n",
    "                            }\n",
    "                       },\n",
    "                        \"category\": category\n",
    "                    }\n",
    "                dictionary[\"objects\"].append(object_dictionary)\n",
    "            dictionaries.append(dictionary)\n",
    "            filename = \"{}.json\".format(groups[1])\n",
    "            with open(filename, \"w\") as stream:\n",
    "                json.dump(dictionaries, stream)#dumps是将dict转化成str格式，loads是将str转化成dict格式。\n",
    "\n",
    "\n",
    "#得到training1.json和test.jsonnaries, stream)#dumps是将dict转化成str格式，loads是将str转化成dict格式。\n",
    "\n",
    "\n",
    "#得到training1.json和test.json     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A simple example for ploting two figures of a exponential\n",
    "function in order to test the autonomy of the gallery\n",
    "stacking multiple images.\n",
    "\"\"\"\n",
    "\n",
    "import keras\n",
    "import keras_rcnn\n",
    "import keras_rcnn.datasets.shape \n",
    "import keras_rcnn.preprocessing\n",
    "import keras_rcnn.models\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import jsonschema\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    resource_path = \"/\".join([\"data1\", \"schema.json\"])\n",
    "\n",
    "    with open(pkg_resources.resource_filename(\"keras_rcnn\", resource_path)) as stream:\n",
    "        schema = json.load(stream)\n",
    "\n",
    "    resource_path = \"/\".join([\"data1\", \"shape\", \"training3.json\"])\n",
    "\n",
    "    with open(pkg_resources.resource_filename(\"keras_rcnn\", resource_path)) as stream:\n",
    "        training_dictionary = json.load(stream)\n",
    "\n",
    "    jsonschema.validate(training_dictionary, schema)\n",
    "\n",
    "    for dictionary in training_dictionary:\n",
    "        resource_path = \"/\".join([\"data1\", \"shape\", dictionary[\"image\"][\"pathname\"]])\n",
    "        pathname = pkg_resources.resource_filename(\"keras_rcnn\", resource_path)\n",
    "        dictionary[\"image\"][\"pathname\"] = pathname\n",
    "\n",
    "    resource_path = \"/\".join([\"data1\", \"shape\", \"test3.json\"])\n",
    "\n",
    "    with open(pkg_resources.resource_filename(\"keras_rcnn\", resource_path)) as stream:\n",
    "        test_dictionary = json.load(stream)\n",
    "\n",
    "    jsonschema.validate(test_dictionary, schema)\n",
    "\n",
    "    for dictionary in test_dictionary:\n",
    "        resource_path = \"/\".join([\"data1\", \"shape\", dictionary[\"image\"][\"pathname\"]])\n",
    "        pathname = pkg_resources.resource_filename(\"keras_rcnn\", resource_path)\n",
    "        dictionary[\"image\"][\"pathname\"] = pathname\n",
    "\n",
    "    return training_dictionary, test_dictionary\n",
    "\n",
    "\n",
    "training_dictionary, test_dictionary = load_data()\n",
    "training_dictionary\n",
    "\n",
    "#开始训练模型\n",
    "categories = {\"scratch\":1}\n",
    "\n",
    "generator = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
    "\n",
    "generator = generator.flow_from_dictionary(\n",
    "        dictionary=training_dictionary,\n",
    "        categories=categories,\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "validation_data = keras_rcnn.preprocessing.ObjectDetectionGenerator()\n",
    "validation_data = validation_data.flow_from_dictionary(\n",
    "        dictionary=test_dictionary,\n",
    "        categories=categories,\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "validation_data\n",
    "keras.backend.set_learning_phase(1)\n",
    "model = keras_rcnn.models.RCNN(\n",
    "        categories = {\"scratch\":1},\n",
    "        dense_units=512,\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(optimizer)\n",
    "\n",
    "model.fit_generator(\n",
    "        epochs=3,\n",
    "        generator=generator,\n",
    "        validation_data=validation_data\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
